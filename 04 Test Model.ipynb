{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import keras\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from IPython.display import clear_output\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "def set_update_start():\n",
    "    start_time = datetime.datetime.now()\n",
    "\n",
    "def update_progress(progress):\n",
    "    bar_length = 40\n",
    "    seconds_left = 0;\n",
    "    if isinstance(progress, int):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "    if progress < 0:\n",
    "        progress = 0\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "    if progress > 0:\n",
    "        passed_time = (datetime.datetime.now() - start_time).total_seconds()\n",
    "        seconds_left = (passed_time / progress) - passed_time\n",
    "    block = int(round(bar_length * progress))\n",
    "    clear_output(wait = True)\n",
    "    text = \"Progress: [{0}] {1:.1f}%\".format( \"#\" * block + \"-\" * (bar_length - block), progress * 100)\n",
    "    print(text, \" Remaining: \" + ':'.join(str(datetime.timedelta(seconds=seconds_left)).split('.')[:1]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ngrams(text):\n",
    "    ngrams = { }\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'([a-z])[-\\.\\/\\\\]([a-z])', r'\\1\\2', text) #cross-site => crosssite , E-commerce => ecommerce\n",
    "    bigrams = []\n",
    "    trigrams = []\n",
    "    monograms = []\n",
    "    words = keras.preprocessing.text.text_to_word_sequence(text, filters='\\'!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=' ')\n",
    "    n_minus_one_word = None\n",
    "    n_minus_two_word = None\n",
    "    for word in words:\n",
    "        if not n_minus_one_word == None:\n",
    "            bigrams.append(\"\".join([n_minus_one_word, '|', word]))\n",
    "        if not n_minus_two_word == None:\n",
    "            trigrams.append(\"\".join([n_minus_two_word, '|', n_minus_one_word, '|', word]))\n",
    "        monograms.append(word)\n",
    "        n_minus_two_word = n_minus_one_word\n",
    "        n_minus_one_word = word\n",
    "    ngrams['monograms'] = monograms\n",
    "    ngrams['bigrams'] = bigrams\n",
    "    ngrams['trigrams'] = trigrams\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cves = pd.read_csv('model/test_data.csv')\n",
    "total_grams = all_cves['CVE'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "monograms = pd.read_csv('model/token_frequencies_monograms.csv')\n",
    "bigrams = pd.read_csv('model/token_frequencies_bigrams.csv')\n",
    "trigrams = pd.read_csv('model/token_frequencies_trigrams.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_cve(description):\n",
    "\n",
    "# sum and count monograms, bigrams and trigrams separately\n",
    "\n",
    "# rewrite this to MERGE the data frames to prevent the filter on the inner loop\n",
    "\n",
    "    monogram_hits = 0\n",
    "    monogram_boolean_score = 0\n",
    "    monogram_complex_score = 0\n",
    "    bigram_hits = 0\n",
    "    bigram_boolean_score = 0\n",
    "    bigram_complex_score = 0\n",
    "    trigram_hits = 0\n",
    "    trigram_boolean_score = 0\n",
    "    trigram_complex_score = 0\n",
    "    \n",
    "    ngrams = build_ngrams(description)\n",
    "    for token in ngrams['monograms']:\n",
    "        value = monograms[monograms['Token'] == token]\n",
    "        if (len(value) != 0):\n",
    "            monogram_hits = monogram_hits + 1\n",
    "            monogram_boolean_score = monogram_boolean_score + (int(value['Exploitable']) / int(value['Count']))\n",
    "            monogram_complex_score = monogram_complex_score + ((int(value['ExploitDB']) + int(value['Snort'])) / int(value['Count']))\n",
    "    for token in ngrams['bigrams']:\n",
    "        value = bigrams[bigrams['Token'] == token]\n",
    "        if (len(value) != 0):\n",
    "            bigram_hits = bigram_hits + 1\n",
    "            bigram_boolean_score = bigram_boolean_score + (int(value['Exploitable']) / int(value['Count']))\n",
    "            bigram_complex_score = bigram_complex_score + ((int(value['ExploitDB']) + int(value['Snort'])) / int(value['Count']))\n",
    "    for token in ngrams['trigrams']:\n",
    "        value = trigrams[trigrams['Token'] == token]\n",
    "        if (len(value) != 0):\n",
    "            trigram_hits = trigram_hits + 1\n",
    "            trigram_boolean_score = trigram_boolean_score + (int(value['Exploitable']) / int(value['Count']))\n",
    "            trigram_complex_score = trigram_complex_score + ((int(value['ExploitDB']) + int(value['Snort'])) / int(value['Count']))\n",
    "    return { \n",
    "                'monogram_hits'          : monogram_hits,\n",
    "                'monogram_boolean_score' : monogram_boolean_score,\n",
    "                'monogram_complex_score' : monogram_complex_score,\n",
    "                'bigram_hits'            : bigram_hits,\n",
    "                'bigram_boolean_score'   : bigram_boolean_score,\n",
    "                'bigram_complex_score'   : bigram_complex_score,\n",
    "                'trigram_hits'           : trigram_hits,\n",
    "                'trigram_boolean_score'  : trigram_boolean_score,\n",
    "                'trigram_complex_score'  : trigram_complex_score\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def largest_score(score):\n",
    "    scores = []\n",
    "    scores.append(score['monogram_boolean_score'] / score['monogram_hits'])\n",
    "    scores.append(score['monogram_complex_score'] / score['monogram_hits'])\n",
    "    scores.append(score['bigram_boolean_score']   / score['bigram_hits'])\n",
    "    scores.append(score['bigram_complex_score']   / score['monogram_hits'])\n",
    "    scores.append(score['trigram_boolean_score']  / score['trigram_hits'])\n",
    "    scores.append(score['trigram_complex_score']  / score['monogram_hits'])\n",
    "\n",
    "    return numpy.amax(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [#---------------------------------------] 2.0%  Remaining: 2 days, 5:53:54\n"
     ]
    }
   ],
   "source": [
    "size = len(test_cves.index)\n",
    "row_accumulator = []\n",
    "counter = 0\n",
    "\n",
    "set_update_start()\n",
    "for index, row in test_cves.iterrows():\n",
    "    counter = counter + 1\n",
    "    update_progress(counter / size)\n",
    "    score = score_cve(row['Description'])\n",
    "    lg_score = largest_score(score)\n",
    "    #print(row['CVE'], row['ExploitDB'], row['Snort'])\n",
    "    #print(row['Description'])\n",
    "    #print('mono :', score['monogram_boolean_score'] / score['monogram_hits'], score['monogram_complex_score'] / score['monogram_hits'])\n",
    "    #print('bi   :', score['bigram_boolean_score'] / score['bigram_hits'], score['bigram_complex_score'] / score['monogram_hits'])\n",
    "    #print('tri  :', score['trigram_boolean_score'] / score['trigram_hits'], score['trigram_complex_score'] / score['monogram_hits'])\n",
    "    #print('combo:', (score['monogram_boolean_score'] + score['bigram_boolean_score'] + score['trigram_boolean_score']) / (score['monogram_hits'] + score['bigram_hits'] + score['trigram_hits']), \n",
    "    #                (score['monogram_complex_score'] + score['bigram_complex_score'] + score['trigram_complex_score']) / (score['monogram_hits'] + score['bigram_hits'] + score['trigram_hits']))\n",
    "\n",
    "    #print(score)\n",
    "    #print()\n",
    "    new_row = { 'CVE': row['CVE'], 'Snort': row['Snort'], 'ExploitDB': row['ExploitDB'], 'Score': lg_score }\n",
    "    row_accumulator.append(new_row)            \n",
    "    \n",
    "test_results = pd.DataFrame(row_accumulator)\n",
    "test_results.to_csv('model/test_results.csv',index=False)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
